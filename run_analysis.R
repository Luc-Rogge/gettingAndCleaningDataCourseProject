# Function to load and merge test and train datasets, selecting only the mean/std features columns

merge.datasets <- function()
   {
   # Load reference tables

   activities <- read.table("activity_labels.txt", sep=" ", header=FALSE, col.names=c("activity.id", "activity.name"))

   features <- read.table("features.txt", sep=" ", header=FALSE, col.names=c("index", "name"))

   features$width <- rep(16, nrow(features)) # each feature column is 16 bytes wide


   # Find mean and standard deviations features, based on their names
   # Hint: grepl() returns a logical telling if the pattern is present or not; fixed = TRUE tells to check the pattern as it, without using regular expressions
   
   features$selected <- grepl("-mean()", features$name, fixed = TRUE) | grepl("-std()", features$name, fixed = TRUE)

   # After the selection, fix the names so that they are usable as column names in R
   features$name <- sub("()", "", features$name, fixed = TRUE) # remove ()
   features$name <- sub("-", ".", features$name, fixed = TRUE) # replace dashes with dots


   # Sub-function to load a dataset (id = "test" or "train")

   load.dataset <- function(id)
   {
     # Hint: paste0() simply concatenates characters without adding separators
 
     # Load the subject ids
     path <- paste0(id, "/subject_", id, ".txt") #eg "test" -> "test/subject_test.txt"
     subject.id <- read.table(path, header=FALSE, col.names="subject.id")$subject.id

     # Load the activity ids (Y) into a new column activity.id
     path <- paste0(id, "/y_", id, ".txt") #eg "test" -> "test/y_test.txt"
     activity.id <- read.table(path, header=FALSE, col.names="activity.id")$activity.id

     # Load the x data (features values) by chunks of 500 rows, as the whole dataset with all features doesn't fit into 4GB
     expectedRows <- length(activity.id)
     maxChunkRows <- 500
     readRows <- 0
     dataset <- NULL
     path <- paste0(id, "/x_", id, ".txt") #eg "test" -> "test/x_test.txt"

     while (readRows < expectedRows)
     {
        # Load a chunk with all the features (not very efficient, but we are too close to the deadline to optimize ;)
        # Hint: read.fwf() reads a text file with fixed-width columns (here, each column is 16 characters wide)
        # To read a chunk, we set skip to skip the rows that we already read in previous loops, and we set n to set max rows to read in a chunk
        chunk <- read.fwf(path, features$width, header=FALSE, col.names=features$name, n=maxChunkRows, skip=readRows)
        chunkRows <- nrow(chunk)

        # Extract only the measurements on the mean and standard deviation for each measurement
        # Done right after loading, to free memory as soon as possible
        chunk <- chunk[,features$selected]

        # Append the stripped-down (without useless features) chunk to the dataset
        dataset = if(is.null(dataset)) chunk else rbind(dataset, chunk)
        readRows <- readRows + chunkRows
     }

     # Add the column subject.id
     dataset$subject.id <- subject.id

     # Add the column activity.id
     dataset$activity.id <- activity.id

     # Merge/join on activity.id to add the activity.label column
     dataset <- merge(dataset, activities)
     dataset$activity.id <- NULL # we don't need activity.id anymore, we keep just activity.name

     # Return the merged data
     # The variables are named: activity.name, subject.id + the descriptive names of the 66 mean/std features as provided in features.txt
     dataset    
   }



   # Return the merged training and test datasets

   rbind(load.dataset("test"), load.dataset("train"))
}


# Function to compute the average of the features of the dataset, grouped by activity, subject

summarize.dataset <- function(ds)
{
   # Get a logical filter on the feature columns to average, that is: all the columns except "subject.id" and "activity.name"
   features <- !colnames(ds) %in% c("subject.id", "activity.name")

   # Aggregate the feature columns by activity.name, subject.id
   # Hint: aggregate() is more handy to aggregate on a list of variables known only at runtime (= dynamically loaded from features.txt)
   means <- aggregate(ds[,features],FUN=mean,by=list(ds$activity.name,ds$subject.id))

   # Rename the Group.1, Group.2 columns generated by aggregate, with more descriptive names
   # NB could also be done by a mutate()
   cnames <- colnames(means)
   cnames[cnames == "Group.2"] <- "subject.id" # rename Group.2 as subject.id
   cnames[cnames == "Group.1"] <- "activity.name" # rename Group.1 as activity.name
   colnames(means) <- cnames

   # The variables now are named: activity.name, subject.id + the descriptive names of the 66 mean/std features as provided in features.txt

   # Returns the aggregated data
   means
}


# Bring it all together

run_analysis <- function()
{
   # Load the full dataset
   full_dataset <- merge.datasets()

   # Compute and return the summary
   summarize.dataset(full_dataset)
}